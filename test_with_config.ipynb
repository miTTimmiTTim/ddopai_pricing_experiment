{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '1'\n",
    "\n",
    "import logging\n",
    "import numexpr as ne\n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "from ddopai.envs.pricing.dynamic import DynamicPricingEnv\n",
    "from ddopai.envs.pricing.dynamic_RL2 import RL2DynamicPricingEnv\n",
    "from ddopai.envs.pricing.dynamic_lag import LagDynamicPricingEnv\n",
    "from ddopai.envs.pricing.dynamic_inventory import DynamicPricingInvEnv\n",
    "from ddopai.envs.actionprocessors import ClipAction, RoundAction\n",
    "from ddopai.agents.obsprocessors import ConvertDictSpace\n",
    "\n",
    "from ddopai.experiments.experiment_functions_online import run_experiment \n",
    "from ddopai.experiments.meta_experiment_functions import *\n",
    "import requests\n",
    "import yaml\n",
    "import re\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import gc\n",
    "#from mushroom_rl import core \n",
    "from ddopai.experiments.meta_core import Core\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_level = logging.INFO\n",
    "logging.basicConfig(level=logging_level)\n",
    "\n",
    "ne.set_num_threads(1)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "set_warnings(logging.INFO) # turn off warnings for any level higher or equal to the input level\n",
    "LIBRARIES_TO_TRACK = [\"ddopai\", \"mushroom_rl\"]\n",
    "PROJECT_NAME = \"pricing_cMDP_test\"\n",
    "\n",
    "ENVCLASS = DynamicPricingEnv\n",
    "RESULTS_DIR = \"results\"\n",
    "def get_ENVCLASS(class_name):\n",
    "    if class_name == \"DynamicPricingEnv\":\n",
    "        return DynamicPricingEnv\n",
    "    elif class_name == \"DynamicPricingInvEnv\":\n",
    "        return DynamicPricingInvEnv\n",
    "    elif class_name == \"LagDynamicPricingEnv\":\n",
    "        return LagDynamicPricingEnv\n",
    "    elif class_name == \"RL2DynamicPricingEnv\":\n",
    "        return RL2DynamicPricingEnv\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown class name {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment preparations\n",
    "## Set-up WandB\n",
    "### Init WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"pricing_cMDP\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track library versions and git hash of experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtimlachner\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/timlachner/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai_pricing_experiments/wandb/run-20250411_133706-5kdasfgd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/timlachner/pricing_cMDP_test/runs/5kdasfgd' target=\"_blank\">pricing_cMDP_test_2025-04-11_13-37-05</a></strong> to <a href='https://wandb.ai/timlachner/pricing_cMDP_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/timlachner/pricing_cMDP_test' target=\"_blank\">https://wandb.ai/timlachner/pricing_cMDP_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/timlachner/pricing_cMDP_test/runs/5kdasfgd' target=\"_blank\">https://wandb.ai/timlachner/pricing_cMDP_test/runs/5kdasfgd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ddopai: 0.0.7\n",
      "INFO:root:mushroom_rl: 1.10.1\n",
      "INFO:root:Git hash: 0240bca214a0886c93a097164834526abebcdb70\n",
      "INFO:root:Configuration file 'config_train.yaml' successfully loaded.\n",
      "INFO:root:Configuration file 'config_agent.yaml' successfully loaded.\n",
      "INFO:root:Configuration file 'config_env.yaml' successfully loaded.\n",
      "WARNING:root:No lag window specified in the agent configuration. Keeping value from env config\n"
     ]
    }
   ],
   "source": [
    "config_train, config_agent, config_env, AgentClass, agent_name = prep_experiment(\n",
    "        PROJECT_NAME,\n",
    "        LIBRARIES_TO_TRACK,\n",
    "        config_train_name=\"config_train.yaml\",\n",
    "        config_agent_name=\"config_agent.yaml\",\n",
    "        config_env_name=\"config_env.yaml\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_env['lag_window_params'].get(\"lag_window\") is not None:\n",
    "        for env_kwargs in config_env[\"env_kwargs\"]:\n",
    "            env_kwargs[\"lag_window\"] = config_env['lag_window_params']['lag_window']\n",
    "            env_kwargs[\"env_class\"] = \"LagDynamicPricingEnv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artifact = wandb.use_artifact('raw_data:latest')\n",
    "#path = artifact.download()\n",
    "#raw_data = pickle.load(open(os.path.join(path, 'raw_data.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data, val_index_start, test_index_start = get_online_data(\n",
    "            config_env,\n",
    "            overwrite=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.17042525, 0.02231759, 0.37522929, 0.41223724,\n",
       "       0.01571206, 0.48614612, 0.42916275, 0.19386668, 0.10603631])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment parameters\n",
    "\n",
    "* Get the environment parameters from the config file \n",
    "* Overwrite the ```lag_window```parameter with the parameter specified in the agent, if it is specified (since lag window is provided by the environment, but a tunable hyperparameter of the agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_action = RoundAction(unit_size=config_env[\"unit_size\"])\n",
    "clip_action = ClipAction(low =config_env[\"setup_kwargs\"][])\n",
    "postprocessors = [round_action]\n",
    "\n",
    "#ENVCLASS = get_ENVCLASS(config_env[\"env_class\"])\n",
    "#environment = set_up_env_online(ENVCLASS, raw_data, val_index_start, test_index_start, config_env, postprocessors)\n",
    "environments = prepare_env_online(get_ENVCLASS=get_ENVCLASS, raw_data=raw_data, val_index_start=0, test_index_start=0, config_env=config_env, postprocessors=postprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2000.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environments[0].inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('features': Box([1.0000000e+00 1.4287769e-04 3.8245969e-04 9.3830319e-04 2.1704179e-04\n",
       " 2.1403281e-03 8.0802059e-04 1.9769531e-03 2.2935087e-03 2.8973455e-03], [1.         0.49980804 0.49928105 0.49585605 0.49503562 0.49853876\n",
       " 0.49922723 0.49936512 0.4979667  0.4993368 ], (10,), float32), 'inventory': Box(0.0, 1.0, (1,), float32), 'prev_action': Box(0.0, 20.0, (1,), float32), 'prev_done': Box(0.0, 1.0, (1,), float32), 'prev_reward': Box(-inf, inf, (1,), float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environments[0].observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': array([1.        , 0.17042525, 0.02231759, 0.37522929, 0.41223724,\n",
       "        0.01571206, 0.48614612, 0.42916275, 0.19386668, 0.10603631]),\n",
       " 'inventory': array([[1.]], dtype=float32),\n",
       " 'prev_action': array([0.], dtype=float32),\n",
       " 'prev_reward': array([0.], dtype=float32),\n",
       " 'prev_done': array([1.], dtype=float32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, _ = environments[0].get_observation()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.17042525, 0.02231759, 0.37522929, 0.41223724,\n",
       "       0.01571206, 0.48614612, 0.42916275, 0.19386668, 0.10603631,\n",
       "       1.        , 0.        , 0.        , 1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = ConvertDictSpace(keep_time_dim=False)\n",
    "X = conv(environments[0].get_observation()[0])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Agent: RL2PPO\n",
      "INFO:root:Actor (RL²) network:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "RL2RNNActor                              [1, 1, 1]                 --\n",
      "├─RL2RNN: 1-1                            [1, 1, 1]                 --\n",
      "│    └─SpecificRNNWrapperHS: 2-1         [1, 1, 64]                --\n",
      "│    │    └─GRU: 3-1                     [1, 1, 64]                15,360\n",
      "│    └─Sequential: 2-2                   [1, 1]                    --\n",
      "│    │    └─Linear: 3-2                  [1, 64]                   4,160\n",
      "│    │    └─ReLU: 3-3                    [1, 64]                   --\n",
      "│    │    └─Dropout: 3-4                 [1, 64]                   --\n",
      "│    │    └─Linear: 3-5                  [1, 32]                   2,080\n",
      "│    │    └─ReLU: 3-6                    [1, 32]                   --\n",
      "│    │    └─Dropout: 3-7                 [1, 32]                   --\n",
      "│    │    └─Linear: 3-8                  [1, 1]                    33\n",
      "==========================================================================================\n",
      "Total params: 21,633\n",
      "Trainable params: 21,633\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.02\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.09\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Critic (RL²) network:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "RL2RNNValue                              [1, 1, 1]                 --\n",
      "├─RL2RNN: 1-1                            [1, 1, 1]                 --\n",
      "│    └─SpecificRNNWrapperHS: 2-1         [1, 1, 64]                --\n",
      "│    │    └─GRU: 3-1                     [1, 1, 64]                15,360\n",
      "│    └─Sequential: 2-2                   [1, 1]                    --\n",
      "│    │    └─Linear: 3-2                  [1, 64]                   4,160\n",
      "│    │    └─ReLU: 3-3                    [1, 64]                   --\n",
      "│    │    └─Dropout: 3-4                 [1, 64]                   --\n",
      "│    │    └─Linear: 3-5                  [1, 32]                   2,080\n",
      "│    │    └─ReLU: 3-6                    [1, 32]                   --\n",
      "│    │    └─Dropout: 3-7                 [1, 32]                   --\n",
      "│    │    └─Linear: 3-8                  [1, 1]                    33\n",
      "==========================================================================================\n",
      "Total params: 21,633\n",
      "Trainable params: 21,633\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.02\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.09\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Agent: {agent_name}\")\n",
    "if agent_name in [\"SAC\", \"PPORNN\", \"RL2PPO\"]:\n",
    "    obsprocessors = [ConvertDictSpace(keep_time_dim=False, )]\n",
    "else:\n",
    "    obsprocessors = []\n",
    "if AgentClass.train_mode == \"env_interaction\":\n",
    "    if \"link\" in config_agent:\n",
    "        glm_link, price_function = set_up_agent(AgentClass, environments[0], config_agent)\n",
    "        config_agent[\"g\"] = glm_link\n",
    "        config_agent[\"price_function\"] = price_function\n",
    "        \n",
    "        del config_agent[\"link\"]\n",
    "    if agent_name == \"Clairvoyant\":\n",
    "        agent = AgentClass(\n",
    "        alpha=environments[0].alpha,\n",
    "        beta=environments[0].beta,\n",
    "        environment_info=environments[0].mdp_info,\n",
    "        **config_agent\n",
    "        )\n",
    "    else:\n",
    "        agent = AgentClass(\n",
    "        environment_info=environments[0].mdp_info,\n",
    "        obsprocessors=obsprocessors,\n",
    "        **config_agent\n",
    "        )\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid train_mode for online training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystoppinghandler = set_up_earlystoppinghandler(config_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'features': array([1.        , 0.00350445, 0.09968054, 0.08908962, 0.00783165,\n",
       "         0.42725708, 0.24546228, 0.4031461 , 0.03825726, 0.02094546]),\n",
       "  'inventory': array([[0.99793303]], dtype=float32),\n",
       "  'prev_action': array([[5.]], dtype=float32),\n",
       "  'prev_reward': array([[20.669678]], dtype=float32),\n",
       "  'prev_done': array([0.], dtype=float32)},\n",
       " array([20.66967708]),\n",
       " array([False]),\n",
       " {'inv': array([1995.86606026]),\n",
       "  'demand': array([4.13393542]),\n",
       "  'demand_noise_free': array([4.96748428]),\n",
       "  'action': array([5.]),\n",
       "  'reward': array([20.66967708])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environments[0].step(np.array([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting experiment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directory: results/5kdasfgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]INFO:root:Epoch 1: R=[-10.06929935], J=[-10.06929935]\n",
      "  0%|          | 1/400 [00:00<00:48,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (204, 1)\n",
      "vpreds (204, 1)\n",
      "tdlam_rets (204, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 2: R=[13.93980706], J=[13.93980706]\n",
      "  0%|          | 2/400 [00:00<00:46,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (223, 1)\n",
      "vpreds (223, 1)\n",
      "tdlam_rets (223, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 3: R=[0.44701754], J=[0.44701754]\n",
      "  1%|          | 3/400 [00:00<00:44,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (211, 1)\n",
      "vpreds (211, 1)\n",
      "tdlam_rets (211, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 4: R=[-9.52421152], J=[-9.52421152]\n",
      "  1%|          | 4/400 [00:00<00:43,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (210, 1)\n",
      "vpreds (210, 1)\n",
      "tdlam_rets (210, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 5: R=[-5.64145389], J=[-5.64145389]\n",
      "  1%|▏         | 5/400 [00:00<00:42,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (205, 1)\n",
      "vpreds (205, 1)\n",
      "tdlam_rets (205, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 6: R=[-5.74289771], J=[-5.74289771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (202, 1)\n",
      "vpreds (202, 1)\n",
      "tdlam_rets (202, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/400 [00:00<00:51,  7.72it/s]INFO:root:Epoch 7: R=[7.08539874], J=[7.08539874]\n",
      "  2%|▏         | 7/400 [00:00<00:47,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (199, 1)\n",
      "vpreds (199, 1)\n",
      "tdlam_rets (199, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 8: R=[-0.27054091], J=[-0.27054091]\n",
      "  2%|▏         | 8/400 [00:00<00:44,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (195, 1)\n",
      "vpreds (195, 1)\n",
      "tdlam_rets (195, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 9: R=[-12.07181465], J=[-12.07181465]\n",
      "  2%|▏         | 9/400 [00:01<00:43,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (202, 1)\n",
      "vpreds (202, 1)\n",
      "tdlam_rets (202, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 10: R=[-11.95891311], J=[-11.95891311]\n",
      "  2%|▎         | 10/400 [00:01<00:45,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (196, 1)\n",
      "vpreds (196, 1)\n",
      "tdlam_rets (196, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 11: R=[-11.62137369], J=[-11.62137369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (192, 1)\n",
      "vpreds (192, 1)\n",
      "tdlam_rets (192, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (194, 1)\n",
      "vpreds (194, 1)\n",
      "tdlam_rets (194, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 12: R=[-12.75330205], J=[-12.75330205]\n",
      "  3%|▎         | 12/400 [00:01<00:42,  9.09it/s]INFO:root:Epoch 13: R=[-2.59301796], J=[-2.59301796]\n",
      "  3%|▎         | 13/400 [00:01<00:41,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (194, 1)\n",
      "vpreds (194, 1)\n",
      "tdlam_rets (194, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 14: R=[-30.49812982], J=[-30.49812982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (178, 1)\n",
      "vpreds (178, 1)\n",
      "tdlam_rets (178, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (176, 1)\n",
      "vpreds (176, 1)\n",
      "tdlam_rets (176, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 15: R=[2.01608156], J=[2.01608156]\n",
      "  4%|▍         | 15/400 [00:01<00:39,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (168, 1)\n",
      "vpreds (168, 1)\n",
      "tdlam_rets (168, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 16: R=[13.78403753], J=[13.78403753]\n",
      "INFO:root:Epoch 17: R=[7.15829537], J=[7.15829537]\n",
      "  4%|▍         | 17/400 [00:01<00:40,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (248, 1)\n",
      "vpreds (248, 1)\n",
      "tdlam_rets (248, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 18: R=[-9.52421152], J=[-9.52421152]\n",
      "  4%|▍         | 18/400 [00:02<00:43,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (282, 1)\n",
      "vpreds (282, 1)\n",
      "tdlam_rets (282, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 19: R=[-14.72214884], J=[-14.72214884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (142, 1)\n",
      "vpreds (142, 1)\n",
      "tdlam_rets (142, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 20: R=[7.30350603], J=[7.30350603]\n",
      "  5%|▌         | 20/400 [00:02<00:43,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (259, 1)\n",
      "vpreds (259, 1)\n",
      "tdlam_rets (259, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 21: R=[-29.51478565], J=[-29.51478565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (135, 1)\n",
      "vpreds (135, 1)\n",
      "tdlam_rets (135, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 22: R=[-21.22055663], J=[-21.22055663]\n",
      "  6%|▌         | 22/400 [00:02<00:38,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (136, 1)\n",
      "vpreds (136, 1)\n",
      "tdlam_rets (136, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 23: R=[-18.33349435], J=[-18.33349435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (132, 1)\n",
      "vpreds (132, 1)\n",
      "tdlam_rets (132, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 24: R=[-3.36184483], J=[-3.36184483]\n",
      "  6%|▌         | 24/400 [00:02<00:34, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (129, 1)\n",
      "vpreds (129, 1)\n",
      "tdlam_rets (129, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 25: R=[-27.71382086], J=[-27.71382086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (126, 1)\n",
      "vpreds (126, 1)\n",
      "tdlam_rets (126, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 26: R=[-15.19356324], J=[-15.19356324]\n",
      "  6%|▋         | 26/400 [00:02<00:32, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (123, 1)\n",
      "vpreds (123, 1)\n",
      "tdlam_rets (123, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 27: R=[-19.57611591], J=[-19.57611591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (121, 1)\n",
      "vpreds (121, 1)\n",
      "tdlam_rets (121, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 28: R=[-43.51377119], J=[-43.51377119]\n",
      "  7%|▋         | 28/400 [00:02<00:29, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (118, 1)\n",
      "vpreds (118, 1)\n",
      "tdlam_rets (118, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (115, 1)\n",
      "vpreds (115, 1)\n",
      "tdlam_rets (115, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 29: R=[-25.94567563], J=[-25.94567563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (111, 1)\n",
      "vpreds (111, 1)\n",
      "tdlam_rets (111, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 30: R=[-27.71382086], J=[-27.71382086]\n",
      "  8%|▊         | 30/400 [00:02<00:27, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (109, 1)\n",
      "vpreds (109, 1)\n",
      "tdlam_rets (109, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 31: R=[-35.40972937], J=[-35.40972937]\n",
      "INFO:root:Epoch 32: R=[-35.55758666], J=[-35.55758666]\n",
      "  8%|▊         | 32/400 [00:03<00:27, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (105, 1)\n",
      "vpreds (105, 1)\n",
      "tdlam_rets (105, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 33: R=[-23.02819633], J=[-23.02819633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (101, 1)\n",
      "vpreds (101, 1)\n",
      "tdlam_rets (101, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 34: R=[-47.68878083], J=[-47.68878083]\n",
      "  8%|▊         | 34/400 [00:03<00:25, 14.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (100, 1)\n",
      "vpreds (100, 1)\n",
      "tdlam_rets (100, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 35: R=[-80.58963942], J=[-80.58963942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (97, 1)\n",
      "vpreds (97, 1)\n",
      "tdlam_rets (97, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 36: R=[-46.55182556], J=[-46.55182556]\n",
      "  9%|▉         | 36/400 [00:03<00:23, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (94, 1)\n",
      "vpreds (94, 1)\n",
      "tdlam_rets (94, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 37: R=[-51.65915504], J=[-51.65915504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (91, 1)\n",
      "vpreds (91, 1)\n",
      "tdlam_rets (91, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 38: R=[-83.99128347], J=[-83.99128347]\n",
      " 10%|▉         | 38/400 [00:03<00:22, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (89, 1)\n",
      "vpreds (89, 1)\n",
      "tdlam_rets (89, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 39: R=[-54.0268635], J=[-54.0268635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (86, 1)\n",
      "vpreds (86, 1)\n",
      "tdlam_rets (86, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 40: R=[-71.28794721], J=[-71.28794721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (84, 1)\n",
      "vpreds (84, 1)\n",
      "tdlam_rets (84, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (81, 1)\n",
      "vpreds (81, 1)\n",
      "tdlam_rets (81, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 41: R=[-93.47712585], J=[-93.47712585]\n",
      " 10%|█         | 41/400 [00:03<00:20, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (79, 1)\n",
      "vpreds (79, 1)\n",
      "tdlam_rets (79, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 42: R=[-67.54429717], J=[-67.54429717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (77, 1)\n",
      "vpreds (77, 1)\n",
      "tdlam_rets (77, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 43: R=[-34.23386223], J=[-34.23386223]\n",
      "INFO:root:Epoch 44: R=[-153.51454361], J=[-153.51454361]\n",
      " 11%|█         | 44/400 [00:03<00:18, 19.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (75, 1)\n",
      "vpreds (75, 1)\n",
      "tdlam_rets (75, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 45: R=[-154.81797697], J=[-154.81797697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (74, 1)\n",
      "vpreds (74, 1)\n",
      "tdlam_rets (74, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 46: R=[-120.6253768], J=[-120.6253768]\n",
      " 12%|█▏        | 46/400 [00:03<00:19, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (71, 1)\n",
      "vpreds (71, 1)\n",
      "tdlam_rets (71, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 47: R=[-95.38111569], J=[-95.38111569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (69, 1)\n",
      "vpreds (69, 1)\n",
      "tdlam_rets (69, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 48: R=[-153.25443954], J=[-153.25443954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (69, 1)\n",
      "vpreds (69, 1)\n",
      "tdlam_rets (69, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 49: R=[-165.6892598], J=[-165.6892598]\n",
      " 12%|█▏        | 49/400 [00:03<00:17, 20.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (68, 1)\n",
      "vpreds (68, 1)\n",
      "tdlam_rets (68, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 50: R=[-173.85067849], J=[-173.85067849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (67, 1)\n",
      "vpreds (67, 1)\n",
      "tdlam_rets (67, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (67, 1)\n",
      "vpreds (67, 1)\n",
      "tdlam_rets (67, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 51: R=[-155.60236737], J=[-155.60236737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (66, 1)\n",
      "vpreds (66, 1)\n",
      "tdlam_rets (66, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 52: R=[-177.71915372], J=[-177.71915372]\n",
      " 13%|█▎        | 52/400 [00:04<00:16, 21.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 53: R=[-123.92562693], J=[-123.92562693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (67, 1)\n",
      "vpreds (67, 1)\n",
      "tdlam_rets (67, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 54: R=[-131.12576256], J=[-131.12576256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (67, 1)\n",
      "vpreds (67, 1)\n",
      "tdlam_rets (67, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 55: R=[-125.82857362], J=[-125.82857362]\n",
      " 14%|█▍        | 55/400 [00:04<00:15, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (68, 1)\n",
      "vpreds (68, 1)\n",
      "tdlam_rets (68, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 56: R=[-107.58160501], J=[-107.58160501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (69, 1)\n",
      "vpreds (69, 1)\n",
      "tdlam_rets (69, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 57: R=[-119.45594048], J=[-119.45594048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advs (70, 1)\n",
      "vpreds (70, 1)\n",
      "tdlam_rets (70, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 57/400 [00:04<00:26, 13.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironments\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps_per_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_episodes_per_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearlystoppinghandler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_best\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_step_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRESULTS_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/experiments/experiment_functions_online.py:322\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(agent, envs, n_epochs, n_steps, n_steps_per_fit, n_episodes_per_fit, early_stopping_handler, save_best, performance_criterion, tracking, results_dir, run_id, print_freq, eval_step_info, return_score, return_dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(agent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate_env\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    320\u001b[0m     agent\u001b[38;5;241m.\u001b[39mupdate_env(env)\n\u001b[0;32m--> 322\u001b[0m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps_per_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps_per_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes_per_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_episodes_per_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m dataset \u001b[38;5;241m=\u001b[39m callback\u001b[38;5;241m.\u001b[39mget_dataset()\n\u001b[1;32m    324\u001b[0m info_history \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_info_history() \n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/experiments/meta_core.py:84\u001b[0m, in \u001b[0;36mCore.learn\u001b[0;34m(self, n_steps, n_episodes, n_steps_per_fit, n_episodes_per_fit, render, quiet, record)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     fit_condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_episodes_counter  \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_episodes_per_fit\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_env_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/experiments/meta_core.py:132\u001b[0m, in \u001b[0;36mCore._run\u001b[0;34m(self, n_steps, n_episodes, fit_condition, render, quiet, record, get_env_info, initial_states)\u001b[0m\n\u001b[1;32m    129\u001b[0m     steps_progress_bar \u001b[38;5;241m=\u001b[39m tqdm(disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m     episodes_progress_bar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_episodes, dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, disable\u001b[38;5;241m=\u001b[39mquiet, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 132\u001b[0m dataset, dataset_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmove_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_env_info:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset, dataset_info\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/experiments/meta_core.py:155\u001b[0m, in \u001b[0;36mCore._run_impl\u001b[0;34m(self, move_condition, fit_condition, steps_progress_bar, episodes_progress_bar, render, record, initial_states)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset(initial_states)\n\u001b[0;32m--> 155\u001b[0m sample, step_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_step([sample])\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_steps_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/experiments/meta_core.py:209\u001b[0m, in \u001b[0;36mCore._step\u001b[0;34m(self, render, record)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, render, record):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    Single step.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     agent_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_action\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     action, logpac, vpred \u001b[38;5;241m=\u001b[39m agent_return\n\u001b[1;32m    211\u001b[0m     next_state, reward, absorbing, step_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/agents/base.py:62\u001b[0m, in \u001b[0;36mBaseAgent.draw_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obsprocessor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobsprocessors:\n\u001b[1;32m     60\u001b[0m     observation \u001b[38;5;241m=\u001b[39m obsprocessor(observation) \u001b[38;5;66;03m# applies all preprocessors to the dict observation\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_action_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/agents/rl/mushroom_rl.py:105\u001b[0m, in \u001b[0;36mMushroomBaseAgent.draw_action_\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    102\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_batch_dim(observation)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(observation) \u001b[38;5;66;03m# bypass the agent's draw_action method and directly get prediction from policy network\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/agents/rl/RL2ppo.py:310\u001b[0m, in \u001b[0;36mRL2PPO.draw_action\u001b[0;34m(self, state, return_additional)\u001b[0m\n\u001b[1;32m    308\u001b[0m obs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(state\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    309\u001b[0m actor_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_hidden_state\n\u001b[0;32m--> 310\u001b[0m action, new_actor_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_action_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_hidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_hidden_state \u001b[38;5;241m=\u001b[39m new_actor_hidden_state\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# Evaluate critic with its hidden state:\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/agents/rl/RL2ppo.py:106\u001b[0m, in \u001b[0;36mGaussianTorchPolicyRL2.draw_action_t\u001b[0;34m(self, state, hidden_state)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_action_t\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, hidden_state):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Computes the action given a state and hidden state.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m        new_hidden_state: updated hidden state returned by the regressor.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     dist, new_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     a_raw \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mrsample()\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m#a_than = torch.tanh(a_raw)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m#a_true = a_than * self._delta_a + self._central_a\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m#self._last_a_raw = a_raw\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m#self._last_transformed_a = a_true\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/agents/rl/RL2ppo.py:166\u001b[0m, in \u001b[0;36mGaussianTorchPolicyRL2.distribution_t\u001b[0;34m(self, state, hidden_state)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution_t\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, hidden_state):\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Computes the distribution over actions given state and hidden state.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m            - new_hidden_state is the updated hidden state.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     mu, chol_sigma, new_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean_and_chol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     dist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mMultivariateNormal(loc\u001b[38;5;241m=\u001b[39mmu, scale_tril\u001b[38;5;241m=\u001b[39mchol_sigma, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_dist \u001b[38;5;241m=\u001b[39m dist  \u001b[38;5;66;03m# Save the distribution for later use.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/agents/rl/RL2ppo.py:190\u001b[0m, in \u001b[0;36mGaussianTorchPolicyRL2.get_mean_and_chol\u001b[0;34m(self, state, hidden_state)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_sigma) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Assuming self._mu is now an RNN regressor that takes and returns hidden_state.\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m mu, new_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m chol_sigma \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_sigma))\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mu, chol_sigma, new_hidden_state\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/mushroom_rl/approximators/regressor.py:90\u001b[0m, in \u001b[0;36mRegressor.__call__\u001b[0;34m(self, *z, **predict_params)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mz, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params):\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/mushroom_rl/approximators/regressor.py:138\u001b[0m, in \u001b[0;36mRegressor.predict\u001b[0;34m(self, *z, **predict_params)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39mz, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/mushroom_rl/approximators/_implementations/generic_regressor.py:54\u001b[0m, in \u001b[0;36mGenericRegressor.predict\u001b[0;34m(self, *x, **predict_params)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params):\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    Predict.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/RL_approximators.py:436\u001b[0m, in \u001b[0;36mTorchApproximator.predict\u001b[0;34m(self, output_tensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_cuda:\n\u001b[1;32m    434\u001b[0m     torch_args \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mas_tensor(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m    435\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 436\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtorch_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_tensor:\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/RL_approximators.py:1263\u001b[0m, in \u001b[0;36mRL2RNNActor.forward\u001b[0;34m(self, state, hidden_state)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, hidden_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;124;03m    Forward pass.\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m    Outputs continuous action mean only.\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1263\u001b[0m     mean, hidden_state_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean, hidden_state_new\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/RL_approximators.py:753\u001b[0m, in \u001b[0;36mRL2RNN.forward\u001b[0;34m(self, x, hidden_state)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    752\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure shape is [B, 1, input_dim]\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m rnn_out, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# rnn_out: [B, T, H]\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# Instead of taking only the last time step:\u001b[39;00m\n\u001b[1;32m    756\u001b[0m B, T, H \u001b[38;5;241m=\u001b[39m rnn_out\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Work/DDOP/ddopai/ddopai/RL_approximators.py:85\u001b[0m, in \u001b[0;36mRNNWrapperHS.forward\u001b[0;34m(self, x, hidden_state)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    Forward pass of the RNN.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        hidden_state: Hidden state for the next timestep\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     output, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, hidden_state\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ddop/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1392\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1392\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1405\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1406\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1414\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = run_experiment(\n",
    "        agent,\n",
    "        environments[:1],\n",
    "        n_epochs=config_train[\"n_epochs\"],\n",
    "        n_steps=config_train[\"n_steps\"],\n",
    "        n_steps_per_fit=None,\n",
    "        n_episodes_per_fit=1,\n",
    "        early_stopping_handler=earlystoppinghandler,\n",
    "        save_best=config_train[\"save_best\"],\n",
    "        run_id=wandb.run.id,\n",
    "        tracking=\"wandb\",\n",
    "        eval_step_info=False,\n",
    "        print_freq=1,\n",
    "        results_dir = RESULTS_DIR,\n",
    "        return_dataset=True,\n",
    "        return_score=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Action</td><td>▄▇▁▆▄▃▅▄▄▂▅▆▆▄▃▇▄▇▆▇▆▆▃▄▄▁▆▅█▆▄▇▆▇██▂▄▆▆</td></tr><tr><td>Cumulative_Reward</td><td>▁▁▁▁▅▃▃▂▄▅▂▄▄▂▃▃▂▄▂▄▃▃▆▃▂▂▅▄▂▅▅▂▂▃▃▂▆▅▆█</td></tr><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>Inventory</td><td>▆█▂▃▂▅▇▂█▁▄▂▁▃▅▇▃██▄▆▅▇▆▁▃▂█▄▃▂█▆▄▃▁▅▁▂█</td></tr><tr><td>Reward</td><td>▆▇▄▆▄▄▅▆▅█▅▅█▆▅▅▆▆▆▆▆▁▆▄▇▅█▄█▆▅▅▆▃▁▆▂▃▆▅</td></tr><tr><td>t</td><td>▃▂▂▃▁▂▂▁▆█▆▃▇▇▂▁▄▇▁▃▂▇▆▃▇▄▅▆▇█▅▄▁▅▇▂▅▂▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Action</td><td>0.71</td></tr><tr><td>Cumulative_Reward</td><td>1184.4423</td></tr><tr><td>Epoch</td><td>399</td></tr><tr><td>Inventory</td><td>0</td></tr><tr><td>Reward</td><td>3.26642</td></tr><tr><td>t</td><td>220</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pricing_cMDP_test_2025-04-11_13-26-25</strong> at: <a href='https://wandb.ai/timlachner/pricing_cMDP_test/runs/x13yndza' target=\"_blank\">https://wandb.ai/timlachner/pricing_cMDP_test/runs/x13yndza</a><br/> View project at: <a href='https://wandb.ai/timlachner/pricing_cMDP_test' target=\"_blank\">https://wandb.ai/timlachner/pricing_cMDP_test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250411_132625-x13yndza/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
